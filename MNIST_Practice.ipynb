{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnUy9/XUVG/DPytmTlPkYZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR1v-uAbGVYS",
        "colab_type": "text"
      },
      "source": [
        "https://www.geeksforgeeks.org/identifying-handwritten-digits-using-logistic-regression-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjFGUtzsFtj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "16d6ce45-e617-41c6-c309-08e85567d061"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torchvision.datasets as dsets \n",
        "import torchvision.transforms as transforms \n",
        "from torch.autograd import Variable \n",
        "\n",
        "# Hyper Parameters \n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "  \n",
        "# MNIST Dataset (Images and Labels) \n",
        "train_dataset = dsets.MNIST(root ='./data', \n",
        "                            train = True, \n",
        "                            transform = transforms.ToTensor(), \n",
        "                            download = True) \n",
        "  \n",
        "test_dataset = dsets.MNIST(root ='./data', \n",
        "                           train = False, \n",
        "                           transform = transforms.ToTensor()) \n",
        "  \n",
        "# Dataset Loader (Input Pipline) \n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True) \n",
        "  \n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = False) \n",
        "  \n",
        "# Model \n",
        "class LogisticRegression(nn.Module): \n",
        "    def __init__(self, input_size, num_classes): \n",
        "        super(LogisticRegression, self).__init__() \n",
        "        self.linear = nn.Linear(input_size, num_classes) \n",
        "  \n",
        "    def forward(self, x): \n",
        "        out = self.linear(x) \n",
        "        return out \n",
        "  \n",
        "  \n",
        "model = LogisticRegression(input_size, num_classes) \n",
        "  \n",
        "# Loss and Optimizer \n",
        "# Softmax is internally computed. \n",
        "# Set parameters to be updated. \n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
        "  \n",
        "# Training the Model \n",
        "for epoch in range(num_epochs): \n",
        "    for i, (images, labels) in enumerate(train_loader): \n",
        "        images = Variable(images.view(-1, 28 * 28)) \n",
        "        labels = Variable(labels) \n",
        "  \n",
        "        # Forward + Backward + Optimize \n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(images) \n",
        "        loss = criterion(outputs, labels) \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "  \n",
        "        if (i + 1) % 100 == 0: \n",
        "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, \n",
        "                     len(train_dataset) // batch_size, loss.item())) \n",
        "  \n",
        "# Test the Model \n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader: \n",
        "    images = Variable(images.view(-1, 28 * 28)) \n",
        "    outputs = model(images) \n",
        "    _, predicted = torch.max(outputs.data, 1) \n",
        "    total += labels.size(0) \n",
        "    correct += (predicted == labels).sum() \n",
        "  \n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % ( \n",
        "            100 * correct / total)) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2405\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0815\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 1.9932\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9317\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8657\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8251\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.7200\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6403\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.6595\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5760\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.4678\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.5021\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4192\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3588\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3195\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.3646\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.2962\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2662\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.1969\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.3631\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.2200\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.1846\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.0751\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0577\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1674\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0906\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.0829\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0170\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.9375\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0676\n",
            "Accuracy of the model on the 10000 test images:  82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XLMXDA1Fwx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}